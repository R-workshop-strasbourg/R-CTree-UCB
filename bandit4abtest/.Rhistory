lines(alpha, cum_reg_random_alloc , pch=19,  type="b", lty=5, col ="black")
# Ajouter une légende
legend(1.8,135000, legend=c("Ctreeucb", "LinUCB","UCB","KernelUCB", "Uniform"),
col=c("green", "blue","brown", "red", "black"), pch=15:20, lty=1:5 ,cex=0.5)
rm()
cum_reg_ctree= c(4873,4779,4884,5337,5807,6266,6696)
L <- c((4873+2*40),4779+2*11,4884+2*14,5337+2*24,5807+2*16,6266+2*19,6696+2*22)
U  <- c((4873-2*40),4779+2*11,4884-2*14,5337-2*24,5807-2*16,6266-2*19,6696-2*22)
cum_reg_ucb_alloc = c(7842,7878,7851,7878,7920,7975,8041)
cum_reg_linucb = c(5015,5036,5050,5080,5146,5225,5311)
cum_reg_kernelucb = c(13714,13580,13713,13524,13628,13562,13715)
cum_reg_random_alloc = c(16281,16281,16281,16281,16281,16281,16281)
alpha <- c(0,0.25,0.5,1,1.5,2,2.5)
library(ggplot2)
#pdf(paste("/home/manue/Documents/manue/Manipulation/datascience-emmanuelle/programme_R/bandit/xp ctree_ucb/exp1/2000/Graph_comparaison",".pdf",sep=""))
comp_reg <- data.frame(cbind(cum_reg_ctree,
cum_reg_ucb_alloc,
cum_reg_linucb,
cum_reg_kernelucb,
cum_reg_random_alloc))
colnames(comp_reg) <- c("Ctreeucb", "UCB", "LinUCB", "KernelUCB", "Uniform")
#par(mar=c(5.1, 4.1, 4.1, 8.1), xpd=TRUE)
plot(alpha, cum_reg_ctree, type="b", pch=15, lty=1 ,ylim=c(3000,17000),  xlab=expression(alpha), ylab="Cumulative regret", col="green")
# Ajouter une ligne
lines(alpha, cum_reg_linucb, pch=16,  type="b", lty=2,  col="green")
lines(alpha, cum_reg_ucb_alloc, pch=17, type="b", lty=3,  col="brown")
lines(alpha, cum_reg_kernelucb, pch=18,  type="b", lty=4, col="red")
# Ajouter une ligne
lines(alpha, cum_reg_linucb, pch=16,  type="b", lty=2,  col="blue")
#par(mar=c(5.1, 4.1, 4.1, 8.1), xpd=TRUE)
plot(alpha, cum_reg_ctree, type="b", pch=15, lty=1 ,ylim=c(3000,17000),  xlab=expression(alpha), ylab="Cumulative regret", col="green")
# Ajouter une ligne
lines(alpha, cum_reg_linucb, pch=16,  type="b", lty=2,  col="blue")
lines(alpha, cum_reg_ucb_alloc, pch=17, type="b", lty=3,  col="brown")
lines(alpha, cum_reg_kernelucb, pch=18,  type="b", lty=4, col="red")
lines(alpha, cum_reg_random_alloc , pch=19,  type="b", lty=5, col ="black")
# Ajouter une légende
legend(2, 12400, legend=c("Ctreeucb", "LinUCB","UCB","KernelUCB", "Uniform"),
col=c("green", "blue","brown", "red", "black"), pch=15:20, lty=1:5 ,cex=0.5)
size.tot = 1000
set.seed(4649)                          # this makes the example exactly reproducible
x1 = runif(size.tot, min=0, max=10)          # you have 4, largely uncorrelated predictors
x2 = runif(size.tot, min=0, max=10)
x3 = runif(size.tot, min=0, max=10)
x4 = runif(size.tot, min=0, max=10)
dt = cbind(x1,x2,x3,x4)
#arm reward
arm_1 <-  as.vector(c(-1,9,-8,4))
K1 = 1/(1+exp(- crossprod(t(dt),arm_1))) # inverse logit transform of linear predictor
K1 = vapply(K1, function(x) rbinom(1, 1, x), as.integer(1L))
arm_2 <-  as.vector(c(-1,2,1,0))
K2 = 1/(1+exp(- crossprod(t(dt),arm_2))) # inverse logit transform of linear predictor
K2 = vapply(K2, function(x) rbinom(1, 1, x), as.integer(1L))
arm_3 <-  as.vector(c(-1,-5,1,10))
K3 = 1/(1+exp(- crossprod(t(dt),arm_3)))
K3 = vapply(K3, function(x) rbinom(1, 1, x), as.integer(1L))
visitor_reward <-  data.frame(K1,K2,K3)
dt <- as.data.frame(dt)
linucb_bandit <- LinucbBanditObjectEvaluation(dt,visitor_reward)
###UCB policy
ucb_bandit <- UcbBanditObjectEvaluation(visitor_reward,alpha = 1)
#Uniform policy
uniform_bandit <- uniform_bandit_object_evaluation(visitor_reward)
#Thompson Sampling policy
thompson_bandit <- ThompsonSamplingBanditObjectEvaluation(visitor_reward)
##Plot
comp_reg <- data.frame(cbind(
ucb_bandit$cum_reg_ucb_alloc,
linucb_bandit$cum_reg_linucb,
thompson_bandit$cum_reg_ThompsonSampling_alloc,
uniform_bandit$cum_reg_uniform_bandit_alloc))
library(ggplot2)
ggplot(comp_reg, aes(c(1:nrow(comp_reg)), y = value, color = Algorithm)) +
#  geom_line(linetype="dashed",aes(y = my_ctree_ucb$cum_reg_ctree, col = "Ctreeucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = ucb_bandit$cum_reg_ucb_alloc, col = "UCB"),size = 0.5) +
geom_line(linetype="dashed",aes(y = linucb_bandit$cum_reg_linucb, col = "LinUCB"),size = 0.5) +
#  geom_line(linetype="dashed",aes(y = kernel_ucb$cum_reg_kernelucb, col = "KernelUCB"),size = 0.5) +
geom_line(linetype="dashed",aes(y = thompson_bandit$cum_reg_ThompsonSampling_alloc, col = "Thompson Sampling"),size = 0.5) +
geom_line(linetype="dashed",aes(y = uniform_bandit$cum_reg_uniform_bandit_alloc, col = "Uniform"),size = 0.5) +
scale_colour_manual(values =  c("UCB"="brown","LinUCB"="blue","Thompson Sampling"="purple","Uniform"="black"))+
xlab("Time") +
ylab("Cumulative Regret")
##### Pairewise #####
set.seed(1234)
size.tot <- 10000
x <- seq(0, 5, 0.01)
x1<- sample(x, size.tot, replace = TRUE, prob = NULL)
arm_1 <-  as.vector(c(2,-1,1.5,0))
K1 <- (x1 < 1 ) * arm_1[4]  +
(x1 >= 1 & x1 < 2 ) * arm_1[1]  +
(x1 >= 2 & x1 < 3) * arm_1[2]  +
(x1 >= 3 & x1 < 4) * arm_1[3]  +
(x1 >= 4) * arm_1[4]
plot(x1, K1)
arm_2 <-  as.vector(c(1.5,-0.5,1.25,0))
K2 <- (x1 < 1 ) * arm_2[4]  +
(x1 >= 1 & x1 < 2 ) * arm_2[1]  +
(x1 >= 2 & x1 < 3) * arm_2[2]  +
(x1 >= 3 & x1 < 4) * arm_2[3]  +
(x1 >= 4) * arm_2[4]
plot(x1, K2)
#covariate without interest
x2<- sample(x, size.tot, replace = TRUE, prob = NULL)
#Results for each variation
visitor_reward <-  data.frame(K1,K2 )
summary(visitor_reward)
dt <- as.data.frame(cbind(x1,x2))
controle_param = ctreeucb_parameters_control_default(dt=dt, visitor_reward=visitor_reward,learn_size=1500,  alpha=1, ctree_control_val= ctree_control(teststat = "quadratic"))
ctreeucb_bandit = ctreeucbBanditObjectEvaluation(dt=dt,visitor_reward,ctree_parameters_control = controle_param )
#take data for online ab test for other algorithm
first <-  ctreeucb_bandit$ctreeucb_bandit_alloc$first_train_element
last <- nrow(visitor_reward)
dt.abtest <- dt[first:last,]
visitor_reward.abtest <- visitor_reward[first:last,]
#compare with linucb bandit
linucb_bandit <- LinucbBanditObjectEvaluation(dt= dt.abtest,visitor_reward = visitor_reward.abtest)
###UCB policy
ucb_bandit <- UcbBanditObjectEvaluation(visitor_reward = visitor_reward.abtest,alpha = 1)
#Uniform policy
uniform_bandit <- uniform_bandit_object_evaluation(visitor_reward = visitor_reward.abtest)
#Kernel UCB policy
kernelucb_bandit <- kernelucbBanditObjectEvaluation(dt= dt.abtest,visitor_reward = visitor_reward.abtest)
##Plot
comp_reg <- data.frame(cbind(
ctreeucb_bandit$cum_reg_ctreeucb_bandit_alloc,
ucb_bandit$cum_reg_ucb_alloc,
linucb_bandit$cum_reg_linucb,
uniform_bandit$cum_reg_uniform_bandit_alloc))
library(ggplot2)
ggplot(comp_reg, aes(c(1:nrow(comp_reg)), y = value, color = Algorithm)) +
geom_line(linetype="dashed",aes(y = ctreeucb_bandit$cum_reg_ctreeucb_bandit_alloc, col = "Ctreeucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = ucb_bandit$cum_reg_ucb_alloc, col = "UCB"),size = 0.5) +
geom_line(linetype="dashed",aes(y = linucb_bandit$cum_reg_linucb, col = "LinUCB"),size = 0.5) +
#geom_line(linetype="dashed",aes(y = kernelucb_bandit$cum_reg_kernelucb_bandit_alloc, col = "KernelUCB"),size = 0.5) +
#geom_line(linetype="dashed",aes(y = thompson_bandit$cum_reg_ThompsonSampling_alloc, col = "Thompson Sampling"),size = 0.5) +
geom_line(linetype="dashed",aes(y = uniform_bandit$cum_reg_uniform_bandit_alloc, col = "Uniform"),size = 0.5) +
scale_colour_manual(values =  c("UCB"="brown","LinUCB"="blue","Ctreeucb"="green","Uniform"="black"))+
xlab("Time") +
ylab("Cumulative regret")
###Data format###
df  =  read.table("/home/manue/Documents/manue/GitHub/R-CTree-UCB/bandit4abtest/data/adult.data", sep = ",")  # read text file
df$V1 <- NULL
listCategorial =c("V2","V4","V6","V7","V8","V9")
listInteger  = c("V3","V5","V11","V12","V13")
visitorReward <- as.data.frame(transform_categorial_to_binary( listCategorial = c("V15"), dt=df))
for(i in 1:ncol(visitorReward)) visitorReward[,i] <- as.integer(visitorReward[,i])
###
dt <- df[, c(listCategorial,listInteger)]
dt$V15 <- NULL
#multiply the dataset (if Config 100_100)
#n <- 2
#dt <- do.call("rbind", replicate(n, dt, simplify = FALSE))
#visitorReward  <- do.call("rbind", replicate(n, visitorReward, simplify = FALSE))
dt.old <- dt
set.seed(1234)
####CTREEUCBPARAMETER
## - the size of the learning set is a percent of the all dataset nrow(dt)*0.3 or nrow(dt)*0.5
#  - mincriterion parameter refers to 1 -risk error accepted  (0.99,0.95,0.90)
#  - alpha refers to the dynamic allocation parameter (U.C.B)
#  - arm_for_learn is the original varitation (names(visitorReward)[1] or names(visitorReward)[2] ...or  names(visitorReward)[5] )
#  testtype and teststat is refer to type of test to build the tree (see the paper for more details)
# and are not supposed to be modified#
#Do not multiply the dataset if Config 30_70
#Config 30_70
learn_size = nrow(dt.old)*0.30
#multiply the dataset if Config 100_100
#Config 100_100
#learn_size = nrow(dt.old)*0.5
####CTREEUCBPARAMETER
## - the size of the learning set is already calculated according to the selected configuration (learn_size)
#  - mincriterion parameter refers to 1 -risk error accepted  (0.99,0.95,0.90)
#  - alpha refers to the dynamic allocation parameter (U.C.B)
#  - arm_for_learn is the original varitation (names(visitorReward)[1] or names(visitorReward)[2])
#  testtype and teststat is refer to type of test to build the tree (see the paper for more details)
# and are not supposed to be modified#
ctreeucb_parameters_control <- ctreeucb_parameters_control_default(dt = dt.old,
visitorReward ,
learn_size = learn_size,
alpha = 1,
arm_for_learn = names(visitorReward)[1],
is_reward_are_boolean = TRUE,
ctree_control_val=ctree_control(
mincriterion = 0.99,
testtype = "Teststatistic",
teststat = "quadratic",
splitstat = c( "quadratic"))
)
my_ctree_ucb <- ctreeucbBanditObjectEvaluation(dt= dt.old,visitor_reward=visitorReward, ctree_parameters_control= ctreeucb_parameters_control)
library(bandit4abtest)
library(partykit)
###Data format###
df  =  read.table("/home/manue/Documents/manue/GitHub/R-CTree-UCB/bandit4abtest/data/adult.data", sep = ",")  # read text file
df$V1 <- NULL
listCategorial =c("V2","V4","V6","V7","V8","V9")
library(bandit4abtest)
library(partykit)
###Data format###
df  =  read.table("/home/manue/Documents/manue/GitHub/R-CTree-UCB/bandit4abtest/data/adult.data", sep = ",")  # read text file
df$V1 <- NULL
listCategorial =c("V2","V4","V6","V7","V8","V9")
listInteger  = c("V3","V5","V11","V12","V13")
View(df)
visitorReward <- as.data.frame(transform_categorial_to_binary( listCategorial = c("V15"), dt=df))
for(i in 1:ncol(visitorReward)) visitorReward[,i] <- as.integer(visitorReward[,i])
###
dt <- df[, c(listCategorial,listInteger)]
dt$V15 <- NULL
#multiply the dataset (if Config 100_100)
n <- 2
dt <- do.call("rbind", replicate(n, dt, simplify = FALSE))
visitorReward  <- do.call("rbind", replicate(n, visitorReward, simplify = FALSE))
dt.old <- dt
set.seed(1234)
#multiply the dataset if Config 100_100
#Config 100_100
learn_size = nrow(dt.old)*0.5
ctreeucb_parameters_control <- ctreeucb_parameters_control_default(dt = dt.old,
visitorReward ,
learn_size = learn_size,
alpha = 1,
arm_for_learn = names(visitorReward)[1],
is_reward_are_boolean = TRUE,
ctree_control_val=ctree_control(
mincriterion = 0.99,
testtype = "Teststatistic",
teststat = "quadratic",
splitstat = c( "quadratic"))
)
my_ctree_ucb <- ctreeucbBanditObjectEvaluation(dt= dt.old,visitor_reward=visitorReward, ctree_parameters_control= ctreeucb_parameters_control)
library(bandit4abtest)
library(partykit)
###Data format###
df  =  read.table("/home/manue/Documents/manue/GitHub/R-CTree-UCB/bandit4abtest/data/adult.data", sep = ",")  # read text file
df$V1 <- NULL
listCategorial =c("V2","V4","V6","V7","V8","V9")
listInteger  = c("V3","V5","V11","V12","V13")
visitorReward <- as.data.frame(transform_categorial_to_binary( listCategorial = c("V15"), dt=df))
for(i in 1:ncol(visitorReward)) visitorReward[,i] <- as.integer(visitorReward[,i])
###
dt <- df[, c(listCategorial,listInteger)]
dt$V15 <- NULL
#multiply the dataset (if Config 100_100)
n <- 2
dt <- do.call("rbind", replicate(n, dt, simplify = FALSE))
visitorReward  <- do.call("rbind", replicate(n, visitorReward, simplify = FALSE))
dt.old <- dt
set.seed(1234)
#multiply the dataset if Config 100_100
#Config 100_100
learn_size = nrow(dt.old)*0.5
ctreeucb_parameters_control <- ctreeucb_parameters_control_default(dt = dt.old,
visitorReward ,
learn_size = learn_size,
alpha = 1,
arm_for_learn = names(visitorReward)[1],
is_reward_are_boolean = TRUE,
ctree_control_val=ctree_control(
mincriterion = 0.99,
testtype = "Teststatistic",
teststat = "quadratic",
splitstat = c( "quadratic"))
)
my_ctree_ucb <- ctreeucbBanditObjectEvaluation(dt= dt.old,visitor_reward=visitorReward, ctree_parameters_control= ctreeucb_parameters_control)
library(bandit4abtest)
library(partykit)
###Data format###
df  =  read.table("/home/manue/Documents/manue/GitHub/R-CTree-UCB/bandit4abtest/data/adult.data", sep = ",")  # read text file
df$V1 <- NULL
listCategorial =c("V2","V4","V6","V7","V8","V9")
listInteger  = c("V3","V5","V11","V12","V13")
visitorReward <- as.data.frame(transform_categorial_to_binary( listCategorial = c("V15"), dt=df))
for(i in 1:ncol(visitorReward)) visitorReward[,i] <- as.integer(visitorReward[,i])
###
dt <- df[, c(listCategorial,listInteger)]
dt$V15 <- NULL
#multiply the dataset (if Config 100_100)
n <- 2
dt <- do.call("rbind", replicate(n, dt, simplify = FALSE))
visitorReward  <- do.call("rbind", replicate(n, visitorReward, simplify = FALSE))
dt.old <- dt
set.seed(1234)
#multiply the dataset if Config 100_100
#Config 100_100
learn_size = nrow(dt.old)*0.5
ctreeucb_parameters_control <- ctreeucb_parameters_control_default(dt = dt.old,
visitorReward ,
learn_size = learn_size,
alpha = 1,
arm_for_learn = names(visitorReward)[1],
is_reward_are_boolean = TRUE,
ctree_control_val=ctree_control(
mincriterion = 0.99,
testtype = "Teststatistic",
teststat = "quadratic",
splitstat = c( "quadratic"))
)
my_ctree_ucb <- ctreeucbBanditObjectEvaluation(dt= dt.old,visitor_reward=visitorReward, ctree_parameters_control= ctreeucb_parameters_control)
max(my_ctree_ucb$cum_reg_ctree)
###Data format###
###Other algorithms require binary or continuous variables.
dt <- transform_categorial_to_binary( listCategorial =listCategorial ,listInteger=listInteger, dt=dt)
first <- my_ctree_ucb$ctreeucb_bandit_alloc$first_train_element
last <- nrow(dt)
dt <- dt[first:last,]
visitorReward <- visitorReward[first:last,]
my_linucb_ucb <- LinucbBanditObjectEvaluation(dt=dt, visitor_reward=visitorReward)
max(my_linucb_ucb$cum_reg_linucb)
### Kernel UCB ###
kernel_ucb <-  kernelucbBanditObjectEvaluation(dt=dt, visitor_reward=visitorReward)
max(kernel_ucb$cum_reg_kernelucb)
### Random ###
unif_alloc <- uniform_bandit_object_evaluation(visitor_reward=visitorReward)
max(unif_alloc$cum_reg_uniform_bandit_alloc)
### UCB ###
ucb_alloc <-  UcbBanditObjectEvaluation(visitor_reward=visitorReward,alpha = 1)
max(ucb_alloc$cum_reg_ucb_alloc)
###PLOT WITH GGPLOT2 REGRET###
library(ggplot2)
comp_reg <- data.frame(cbind(my_ctree_ucb$cum_reg_ctree,
ucb_alloc$cum_reg_ucb_alloc,
my_linucb_ucb$cum_reg_linucb,
kernel_ucb$cum_reg_kernelucb,
unif_alloc$cum_reg_uniform_bandit_alloc))
ggplot(comp_reg, aes(c(1:nrow(comp_reg)), y = value, color = Algorithm)) +
geom_line(linetype="dashed",aes(y = my_ctree_ucb$cum_reg_ctree, col = "Ctreeucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = ucb_alloc$cum_reg_ucb_alloc, col = "UCB"),size = 0.5) +
geom_line(linetype="dashed",aes(y = my_linucb_ucb$cum_reg_linucb, col = "LinUCB"),size = 0.5) +
geom_line(linetype="dashed",aes(y = kernel_ucb$cum_reg_kernelucb, col = "KernelUCB"),size = 0.5) +
geom_line(linetype="dashed",aes(y = unif_alloc$cum_reg_uniform_bandit_alloc, col = "Uniform"),size = 0.5) +
scale_colour_manual(values =  c("UCB"="brown","LinUCB"="blue","KernelUCB"="red","Ctreeucb"="green","Uniform"="black"))+
xlab("Time") +
ylab("Cumulative Regret")
View(dt)
View(dt)
####Configuration
#Conf_30/70
config <- "30_70"
df <- abtest1
#Conf_100/100
#config <- "100_100"
#df <-  abtest2
df$langID <- as.factor(df$langID)
df$countryID <- as.factor(df$countryID)
listCategorial =c("countryID","langID","name","device","userAgent")
listInteger  = c("latitude","longitude")
#Results for each variation
visitorReward <- df[,c("A","B")]
#Items caracteristics
dt <- df[, c(listCategorial,listInteger)]
set.seed(1234)
dt.old <- dt
if(config  == "100_100" ) learn_size = 6216
if(config  ==  "30_70"  ) learn_size = 1865
####CTREEUCBPARAMETER
## - the size of the learning set is already calculated according to the selected configuration (learn_size)
#  - mincriterion parameter refers to 1 -risk error accepted  (0.99,0.95,0.90)
#  - alpha refers to the dynamic allocation parameter (U.C.B)
#  - arm_for_learn is the original varitation (names(visitorReward)[1] or names(visitorReward)[2])
#  testtype and teststat is refer to type of test to build the tree (see the paper for more details)
# and are not supposed to be modified#
ctreeucb_parameters_control <- ctreeucb_parameters_control_default(dt = dt.old,
visitorReward ,
learn_size = learn_size,
alpha = 1,
arm_for_learn = names(visitorReward)[1],
is_reward_are_boolean = TRUE,
ctree_control_val=ctree_control(
mincriterion = 0.95,
testtype = "Teststatistic",
teststat = "quadratic",
splitstat = c( "quadratic"))
)
my_ctree_ucb <- ctreeucbBanditObjectEvaluation(dt= dt.old,visitor_reward=visitorReward, ctree_parameters_control= ctreeucb_parameters_control)
max(my_ctree_ucb$cum_reg_ctree)
###END CTREE UCB###
###Data format###
###Other algorithms require binary or continuous variables.
dt <- transform_categorial_to_binary( listCategorial =listCategorial ,listInteger=listInteger, dt=dt)
first <- my_ctree_ucb$ctreeucb_bandit_alloc$first_train_element
last <- nrow(dt)
dt <- dt[first:last,]
visitorReward <- visitorReward[first:last,]
my_linucb_ucb <- LinucbBanditObjectEvaluation(dt=dt, visitor_reward=visitorReward)
max(my_linucb_ucb$cum_reg_linucb)
### END Lin UCB ###
### Kernel UCB ###
kernel_ucb <-  kernelucbBanditObjectEvaluation(dt=dt, visitor_reward=visitorReward)
max(kernel_ucb$cum_reg_kernelucb)
### END Kernel UCB ###
### Random ###
unif_alloc <- uniform_bandit_object_evaluation(visitor_reward=visitorReward)
max(unif_alloc$cum_reg_uniform_bandit_alloc)
### END RANDOM ###
### UCB ###
ucb_alloc <-  UcbBanditObjectEvaluation(visitor_reward=visitorReward,alpha = 1)
max(ucb_alloc$cum_reg_ucb_alloc)
###END UCB###
### PLOT  OF REGRET###
###PLOT WITH GGPLOT2 REGRET###
library(ggplot2)
comp_reg <- data.frame(cbind(my_ctree_ucb$cum_reg_ctree,
ucb_alloc$cum_reg_ucb_alloc,
my_linucb_ucb$cum_reg_linucb,
kernel_ucb$cum_reg_kernelucb,
unif_alloc$cum_reg_uniform_bandit_alloc))
ggplot(comp_reg, aes(c(1:nrow(comp_reg)), y = value, color = Algorithm)) +
geom_line(linetype="dashed",aes(y = my_ctree_ucb$cum_reg_ctree, col = "Ctreeucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = ucb_alloc$cum_reg_ucb_alloc, col = "UCB"),size = 0.5) +
geom_line(linetype="dashed",aes(y = my_linucb_ucb$cum_reg_linucb, col = "LinUCB"),size = 0.5) +
geom_line(linetype="dashed",aes(y = kernel_ucb$cum_reg_kernelucb, col = "KernelUCB"),size = 0.5) +
geom_line(linetype="dashed",aes(y = unif_alloc$cum_reg_uniform_bandit_alloc, col = "Uniform"),size = 0.5) +
scale_colour_manual(values =  c("UCB"="brown","LinUCB"="blue","KernelUCB"="red","Ctreeucb"="green","Uniform"="black"))+
xlab("Time") +
ylab("Cumulative Regret")
df  =  read.csv2("/home/manue/Documents/manue/GitHub/R-CTree-UCB/bandit4abtest/data/movielens.data",sep=";",header = TRUE)
df$X = NULL
dt <- df[,1:19]
visitorReward <- df[,c(20:24)]
###Statistics
temp <-as.data.frame( c(visitorReward[,1] ,visitorReward[,2] ,visitorReward[,3] ,visitorReward[,4], visitorReward[,5] ) )
temp$user <- "0"
temp$user[1:9125] <- "A"
temp$user[9125: 18250] <- "B"
temp$user[18250:27375] <- "C"
temp$user[27375:36500] <- "D"
temp$user[36500:45625] <- "E"
colnames(temp) <- c("valeur","variation")
ajuste <- lm(temp$valeur ~ temp$variation)
summary(ajuste)
anova(ajuste)
a1 <- aov(temp$valeur ~ temp$variation)
posthoc <- TukeyHSD(x=a1, 'temp$variation', conf.level=0.95)
posthoc
#multiply the dataset if Config 100_1OO
n <- 2
dt <- do.call("rbind", replicate(n, dt, simplify = FALSE))
visitorReward  <- do.call("rbind", replicate(n, visitorReward, simplify = FALSE))
dt.old <- dt
set.seed(1234)
####CTREEUCBPARAMETER
## - the size of the learning set is a percent of the all dataset nrow(dt)*0.3 or nrow(dt)*0.5
#  - mincriterion parameter refers to 1 -risk error accepted  (0.99,0.95,0.90)
#  - alpha refers to the dynamic allocation parameter (U.C.B)
#  - arm_for_learn is the original varitation (names(visitorReward)[1] or names(visitorReward)[2] ...or  names(visitorReward)[5] )
#  testtype and teststat is refer to type of test to build the tree (see the paper for more details)
# and are not supposed to be modified#
#Do not multiply the dataset if Config 30_70
#Config 30_70
#learn_size = nrow(dt.old)*0.30
#multiply the dataset if Config 100_100
#Config 100_100
learn_size = nrow(dt.old)*0.5
####CTREEUCBPARAMETER
## - the size of the learning set is already calculated according to the selected configuration (learn_size)
#  - mincriterion parameter refers to 1 -risk error accepted  (0.99,0.95,0.90)
#  - alpha refers to the dynamic allocation parameter (U.C.B)
#  - arm_for_learn is the original varitation (names(visitorReward)[1] or names(visitorReward)[2])
#  testtype and teststat is refer to type of test to build the tree (see the paper for more details)
# and are not supposed to be modified#
library(partykit)
ctreeucb_parameters_control <- ctreeucb_parameters_control_default(dt = dt.old,
visitorReward ,
learn_size = learn_size,
alpha = 1,
arm_for_learn = names(visitorReward)[5],
is_reward_are_boolean = FALSE,
ctree_control_val=ctree_control(
mincriterion = 0.95,
testtype = "Teststatistic",
teststat = "quadratic"
)
)
my_ctree_ucb <- ctreeucbBanditObjectEvaluation(dt= dt.old,visitor_reward=visitorReward, ctree_parameters_control= ctreeucb_parameters_control)
max(my_ctree_ucb$cum_reg_ctree)
###END CTREE UCB###
first <- my_ctree_ucb$ctreeucb_bandit_alloc$first_train_element
last <- nrow(dt)
dt <- dt[first:last,]
visitorReward <- visitorReward[first:last,]
my_linucb_ucb <- LinucbBanditObjectEvaluation(dt=dt, visitor_reward=visitorReward)
max(my_linucb_ucb$cum_reg_linucb)
### END Lin UCB ###
### Kernel UCB ###
dt <- sapply(dt,as.numeric)
kernel_ucb <-  kernelucbBanditObjectEvaluation(dt=dt, visitor_reward=visitorReward)
max(kernel_ucb$cum_reg_kernelucb)
### END Kernel UCB ###
### Random ###
unif_alloc <- uniform_bandit_object_evaluation(visitor_reward=visitorReward)
max(unif_alloc$cum_reg_uniform_bandit_alloc)
### END RANDOM ###
### UCB ###
ucb_alloc <-  UcbBanditObjectEvaluation(visitor_reward=visitorReward,alpha = 1)
max(ucb_alloc$cum_reg_ucb_alloc)
###END UCB###
### PLOT  OF REGRET###
###PLOT WITH GGPLOT2 REGRET###
library(ggplot2)
comp_reg <- data.frame(cbind(my_ctree_ucb$cum_reg_ctree,
ucb_alloc$cum_reg_ucb_alloc,
my_linucb_ucb$cum_reg_linucb,
kernel_ucb$cum_reg_kernelucb,
unif_alloc$cum_reg_uniform_bandit_alloc))
ggplot(comp_reg, aes(c(1:nrow(comp_reg)), y = value, color = Algorithm)) +
geom_line(linetype="dashed",aes(y = my_ctree_ucb$cum_reg_ctree, col = "Ctreeucb"),size = 0.5) +
geom_line(linetype="dashed",aes(y = ucb_alloc$cum_reg_ucb_alloc, col = "UCB"),size = 0.5) +
geom_line(linetype="dashed",aes(y = my_linucb_ucb$cum_reg_linucb, col = "LinUCB"),size = 0.5) +
geom_line(linetype="dashed",aes(y = kernel_ucb$cum_reg_kernelucb, col = "KernelUCB"),size = 0.5) +
geom_line(linetype="dashed",aes(y = unif_alloc$cum_reg_uniform_bandit_alloc, col = "Uniform"),size = 0.5) +
scale_colour_manual(values =  c("UCB"="brown","LinUCB"="blue","KernelUCB"="red","Ctreeucb"="green","Uniform"="black"))+
xlab("Time") +
ylab("Cumulative Regret")
